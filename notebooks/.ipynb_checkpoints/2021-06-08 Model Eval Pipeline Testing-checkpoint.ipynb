{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe66de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d5a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "from datasets import Dataset\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForMaskedLM, DataCollatorForLanguageModeling, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f4e0dd",
   "metadata": {},
   "source": [
    "## 1) Select GPUs to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27fa7b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:0,1,2,3\n"
     ]
    }
   ],
   "source": [
    "gpuids = [0, 1, 2, 3]\n",
    "\n",
    "if gpuids is None or len(gpuids) == 0:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    print(\"Using CPU\")\n",
    "else:\n",
    "    gpuid_str = str(gpuids[0])\n",
    "    for gpuid in gpuids[1:]:\n",
    "        gpuid_str += \",{}\".format(gpuid)\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpuid_str\n",
    "    print(\"Using GPU:{}\".format(gpuid_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52903c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,1,2,3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9dfa732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d7706f",
   "metadata": {},
   "source": [
    "## 2) Set Experiment Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84764125",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    \"model_name_or_path\": \"bert-base-uncased\",\n",
    "    \"tokenizer_name\": \"bert-base-uncased\",\n",
    "    \"cache_dir\": \"/data/ddmg/personalizedmentalhealth/reddit_project/cached_models\",\n",
    "    \"use_fast_tokenizer\": True,\n",
    "    \"config_name_or_path\": \"bert-base-uncased\",\n",
    "}\n",
    "\n",
    "data_args = {\n",
    "    \"data_files\": [\"/data/ddmg/personalizedmentalhealth/reddit_project/data/4_all_data.csv\"],\n",
    "    \"preprocessing_num_workers\": None,  # number of processes to use for the preprocessing\n",
    "    \"mlm_probability\": 0.15,  # ratio of tokens to mask for MLM loss\n",
    "    \"max_eval_samples\": None,  # for debugging purposes, truncate # of evaluation samples to this value if set,\n",
    "    \"data_split\": \"val\",  # evaluate just on this split of data (or all data if None)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef440aa",
   "metadata": {},
   "source": [
    "## 3) Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfe7b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for data_path in data_args[\"data_files\"]:\n",
    "    df = pd.read_csv(data_path)\n",
    "    df.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "    df_list.append(df)\n",
    "data_df = pd.concat(df_list)\n",
    "if data_args[\"data_split\"] is not None:\n",
    "    data_df = data_df[data_df[\"data_split\"] == data_args[\"data_split\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37efd126",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b92ac27",
   "metadata": {},
   "source": [
    "## 4) Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c78a44d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_kwargs = {\n",
    "    \"use_fast\": model_args[\"use_fast_tokenizer\"],\n",
    "    \"cache_dir\": model_args[\"cache_dir\"]\n",
    "}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_args[\"tokenizer_name\"], **tokenizer_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474cdc6b",
   "metadata": {},
   "source": [
    "## 5) Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0865668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_kwargs = {\n",
    "    \"cache_dir\": model_args[\"cache_dir\"]\n",
    "}\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_args[\"config_name_or_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d87706d",
   "metadata": {},
   "source": [
    "## 6) Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2692c88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\n",
    "    model_args[\"model_name_or_path\"],\n",
    "    config=config,\n",
    "    cache_dir=model_args[\"cache_dir\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0cd996",
   "metadata": {},
   "source": [
    "## 7) Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef9d6581",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4c8846fd0504>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/rlm/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         }\n\u001b[1;32m    175\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rlm/lib/python3.8/site-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rlm/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, indices, keep_in_memory, indices_cache_file_name, writer_batch_size, new_fingerprint)\u001b[0m\n\u001b[1;32m   2192\u001b[0m             )\n\u001b[1;32m   2193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2194\u001b[0;31m         \u001b[0mindices_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2195\u001b[0m         \u001b[0;31m# Check if we need to convert indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rlm/lib/python3.8/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rlm/lib/python3.8/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rlm/lib/python3.8/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "dataset = dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92c4c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=False,  # do dynamic padding to longest sequence in batch later\n",
    "        truncation=True,\n",
    "        # We use this option because DataCollatorForLanguageModeling (see below) is more efficient when it\n",
    "        # receives the `special_tokens_mask`.\n",
    "        return_special_tokens_mask=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "230abccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779783beaea642939596232f3262490f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_func,\n",
    "    batched=True,\n",
    "    num_proc=data_args[\"preprocessing_num_workers\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81c2d55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['__index_level_0__', 'attention_mask', 'author', 'created_utc', 'data_split', 'id', 'input_ids', 'special_tokens_mask', 'subreddit', 'text', 'token_type_ids'],\n",
       "    num_rows: 7226\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8358144",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenized_dataset['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6e5a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_args[\"max_eval_samples\"] is not None:\n",
    "    tokenized_dataset = tokenized_dataset.select(range(data_args[\"max_eval_samples\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edf38337",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm_probability=data_args[\"mlm_probability\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e276bd2",
   "metadata": {},
   "source": [
    "## 8) Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cf36018",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90841ba",
   "metadata": {},
   "source": [
    "## 9) Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5dc5caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate()\n",
    "max_eval_samples = data_args[\"max_eval_samples\"] if data_args[\"max_eval_samples\"] is not None else len(dataset)\n",
    "metrics[\"eval_samples\"] = min(max_eval_samples, len(dataset))\n",
    "try:\n",
    "    perplexity = math.exp(metrics[\"eval_loss\"])\n",
    "except OverflowError:\n",
    "    perplexity = float(\"inf\")\n",
    "metrics[\"perplexity\"] = perplexity\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af92aa0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.6866581439971924,\n",
       " 'eval_runtime': 95.2486,\n",
       " 'eval_samples_per_second': 75.865,\n",
       " 'eval_samples': 7226,\n",
       " 'perplexity': 14.682526950967066}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb363488",
   "metadata": {},
   "source": [
    "## 10) Fine-Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea7e1f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_args = {\n",
    "    \"data_files\": [\"/data/ddmg/personalizedmentalhealth/reddit_project/data/4_all_data.csv\"],\n",
    "    \"preprocessing_num_workers\": None,  # number of processes to use for the preprocessing\n",
    "    \"mlm_probability\": 0.15,  # ratio of tokens to mask for MLM loss\n",
    "    \"max_train_samples\": None, # for debugging purposes, truncate # of train samples to this value if set\n",
    "    \"max_eval_samples\": None,  # for debugging purposes, truncate # of evaluation samples to this value if set\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7e5981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for data_path in data_args[\"data_files\"]:\n",
    "    df = pd.read_csv(data_path)\n",
    "    df.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "    df_list.append(df)\n",
    "data_df = pd.concat(df_list)\n",
    "train_df = data_df[data_df[\"data_split\"] == \"train\"]\n",
    "eval_df = data_df[data_df[\"data_split\"] == \"val\"]\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "eval_dataset = Dataset.from_pandas(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57e3ecc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0e511acd1a46c5b9de43057f510adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1365.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(\n",
    "    tokenize_func,\n",
    "    batched=True,\n",
    "    num_proc=data_args[\"preprocessing_num_workers\"]\n",
    ")\n",
    "if data_args[\"max_train_samples\"] is not None:\n",
    "    tokenized_dataset = tokenized_train.select(range(data_args[\"max_train_samples\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f5ee5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec4878fbe58453092d709f9423a584e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_eval = eval_dataset.map(\n",
    "    tokenize_func,\n",
    "    batched=True,\n",
    "    num_proc=data_args[\"preprocessing_num_workers\"]\n",
    ")\n",
    "if data_args[\"max_eval_samples\"] is not None:\n",
    "    tokenized_dataset = tokenized_eval.select(range(data_args[\"max_eval_samples\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2fd4beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b698b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9350' max='127908' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  9350/127908 2:20:39 < 29:43:56, 1.11 it/s, Epoch 0.22/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.930400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.800100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.717200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.695100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.676800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.663300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.650800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.638300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.615900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.616500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.614100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.606600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.592700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.583300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.582600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.569100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.572500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "trainer.save_model()\n",
    "metrics = train_result.metrics\n",
    "max_train_samples = (\n",
    "    data_args[\"max_train_samples\"] if data_args[\"max_train_samples\"] is not None else len(train_dataset)\n",
    ")\n",
    "metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
