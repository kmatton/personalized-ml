{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb79a4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91cd46b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e119f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/generic')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b72798",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Create dataset where:\n",
    "* There are 4 pseudo users --> 2 pairs of users that each come from the same \"base\"/original user\n",
    "* As the validation data, use the full train data from the associated \"base\"/original user\n",
    "    * this way weight matrix learned should reflect the fact that the training data from both pseudo users are useful for optimizing validation performance\n",
    "* As test data, use the test data from the associated base user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7539f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "from dataset.amazon_reviews_clf_dataset import AmazonClfDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5717587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kwargs = dict(\n",
    "    data_dir=\"/data/ddmg/redditlanguagemodeling/data/AmazonReviews/data/amazon_v2.0/\",\n",
    "    raw_data_file=\"reviews.csv\",\n",
    "    tokenizer_name=\"distilbert-base-uncased\",\n",
    "    tokenizer_cache_dir=\"/data/ddmg/redditlanguagemodeling/cached/distilbert\",\n",
    "    split_file=\"wilds_subpop_shift_user.csv\",\n",
    "    processed_data_dir=\"amazon_reviews_clf_processed_with_my_subpop_shift_embeds\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff1a9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading processed data from /data/ddmg/redditlanguagemodeling/data/AmazonReviews/data/amazon_v2.0/amazon_reviews_clf_processed_with_my_subpop_shift_embeds\n"
     ]
    }
   ],
   "source": [
    "dataset = AmazonClfDataset(**data_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdb3df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take users from before (see 2021-09-29 Notebook)\n",
    "user1 = \"A4MO9RO839BEF\"\n",
    "user2 = \"A1B5MN8PY0JIJQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db56e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_dataset(dataset):\n",
    "    users = dataset[\"user\"]\n",
    "    keep_idx = [i for i in range(len(users)) if users[i] in {user1, user2}]\n",
    "    return dataset.select(keep_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4478ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_train_data = get_new_dataset(dataset.train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209c17c",
   "metadata": {},
   "source": [
    "### Create Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e82a4158",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_ids = select_train_data[\"user\"]\n",
    "user1_idx = np.argwhere(np.array(train_user_ids) == user1)\n",
    "user2_idx = np.argwhere(np.array(train_user_ids) == user2)\n",
    "# split these indicies into two groups (one for each pseudo user)\n",
    "p1_index = np.random.choice(user1_idx.flatten(), int(len(user1_idx) / 2), replace=False)\n",
    "p2_index = [elm for elm in user1_idx.flatten() if elm not in p1_index]\n",
    "p3_index = np.random.choice(user2_idx.flatten(), int(len(user2_idx) / 2), replace=False)\n",
    "p4_index = [elm for elm in user2_idx.flatten() if elm not in p3_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fa173d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p1_index) + len(p2_index) + len(p3_index) + len(p4_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deb7e625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4]), array([67, 68, 91, 91]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_users = np.full(317, -1)\n",
    "p_users[p1_index] = \"1\"\n",
    "p_users[p2_index] = \"2\"\n",
    "p_users[p3_index] = \"3\"\n",
    "p_users[p4_index] = \"4\"\n",
    "np.unique(p_users, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fa5eeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_to_o_user = {1: user1, 2: user1, 3: user2, 4: user2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_train_data = select_train_data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "293d86e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add this column to dataset\n",
    "select_train_data = Dataset.from_pandas(select_train_data)  # get rid of old rows in PyArrow Table\n",
    "select_train_data = select_train_data.add_column(name=\"p_user\", column=p_users.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a3775e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(select_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f278a52",
   "metadata": {},
   "source": [
    "### Create Val Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e773e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_val_data = select_train_data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd2ae539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign p_users to be single user\n",
    "def _map_to_single_user(x):\n",
    "    if x == 2:\n",
    "        return 1\n",
    "    if x == 4:\n",
    "        return 3\n",
    "    return x\n",
    "select_val_data[\"p_user\"] = select_val_data[\"p_user\"].apply(lambda x: _map_to_single_user(x))\n",
    "select_val_data2 = select_val_data.copy()\n",
    "def _get_other_p_user(x):\n",
    "    if x == 1:\n",
    "        return 2\n",
    "    return 4\n",
    "select_val_data2[\"p_user\"] = select_val_data[\"p_user\"].apply(lambda x: _get_other_p_user(x))\n",
    "# duplicate each entry and assign as val data for each psuedo user\n",
    "select_val_data = select_val_data.append(select_val_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ab12156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    182\n",
       "3    182\n",
       "2    135\n",
       "1    135\n",
       "Name: p_user, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_val_data[\"p_user\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36732283",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_val_data = select_val_data.drop(columns=\"__index_level_0__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4680284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert back to HF dataset\n",
    "select_val_data = Dataset.from_pandas(select_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c2f2ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "634"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(select_val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf5179",
   "metadata": {},
   "source": [
    "### Create Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "774a64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_test_data = get_new_dataset(dataset.test_data)\n",
    "select_test_data = select_test_data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe3116eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_to_p_user1(user):\n",
    "    if user == user1:\n",
    "        return 1\n",
    "    return 3\n",
    "\n",
    "def user_to_p_user2(user):\n",
    "    if user == user1:\n",
    "        return 2\n",
    "    return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78b0dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_test_data2 = select_test_data.copy()\n",
    "select_test_data[\"p_user\"] = select_test_data[\"user\"].apply(lambda x: user_to_p_user1(x))\n",
    "select_test_data2[\"p_user\"] = select_test_data[\"user\"].apply(lambda x: user_to_p_user2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "546ff954",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_test_data = select_test_data.append(select_test_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2bbbc448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>p_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A4MO9RO839BEF</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1B5MN8PY0JIJQ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1B5MN8PY0JIJQ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1B5MN8PY0JIJQ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1B5MN8PY0JIJQ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>A1B5MN8PY0JIJQ</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>A1B5MN8PY0JIJQ</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>A1B5MN8PY0JIJQ</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>A1B5MN8PY0JIJQ</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>A4MO9RO839BEF</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               user  p_user\n",
       "0     A4MO9RO839BEF       1\n",
       "1    A1B5MN8PY0JIJQ       3\n",
       "2    A1B5MN8PY0JIJQ       3\n",
       "3    A1B5MN8PY0JIJQ       3\n",
       "4    A1B5MN8PY0JIJQ       3\n",
       "..              ...     ...\n",
       "145  A1B5MN8PY0JIJQ       4\n",
       "146  A1B5MN8PY0JIJQ       4\n",
       "147  A1B5MN8PY0JIJQ       4\n",
       "148  A1B5MN8PY0JIJQ       4\n",
       "149   A4MO9RO839BEF       2\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_test_data[[\"user\", \"p_user\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87c0bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_test_data = select_test_data.drop(columns=\"__index_level_0__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97e3486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_test_data = Dataset.from_pandas(select_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a93c778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p_users = np.array(select_train_data[\"p_user\"])\n",
    "val_p_users = np.array(select_val_data[\"p_user\"])\n",
    "test_p_users = np.array(select_test_data[\"p_user\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e68cb96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 2, 3, 4]), array([67, 68, 91, 91]))\n",
      "(array([1, 2, 3, 4]), array([135, 135, 182, 182]))\n",
      "(array([1, 2, 3, 4]), array([75, 75, 75, 75]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train_p_users, return_counts=True))\n",
    "print(np.unique(val_p_users, return_counts=True))\n",
    "print(np.unique(test_p_users, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "acf9a514",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-494f2bb1d6d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# save datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mselect_train_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"amazon_reviews_pseudo_user_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mselect_val_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"amazon_reviews_pseudo_user_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mselect_test_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"amazon_reviews_pseudo_user_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "data_dir = \"/data/ddmg/redditlanguagemodeling/data/AmazonReviews/data\"\n",
    "# save datasets\n",
    "select_train_data.save_to_disk(os.path.join(data_dir, \"amazon_reviews_pseudo_user_data\", \"train\"))\n",
    "select_val_data.save_to_disk(os.path.join(data_dir, \"amazon_reviews_pseudo_user_data\", \"val\"))\n",
    "select_test_data.save_to_disk(os.path.join(data_dir, \"amazon_reviews_pseudo_user_data\", \"test\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
