{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d56709a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40bc477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../src/generic\")\n",
    "import json\n",
    "\n",
    "from dataset.amazon_dataset import AmazonDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0183859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/data/ddmg/redditlanguagemodeling/data/AmazonReviews/data/amazon_v2.0/\"\n",
    "raw_data_file = \"reviews.csv\"\n",
    "processed_data_dir = \"amazon_reviews_processed\"\n",
    "split_file = \"user.csv\"\n",
    "tokenizer_name = \"distilbert-base-uncased\"\n",
    "tokenizer_cache_dir = \"/data/ddmg/redditlanguagemodeling/cached/distilbert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62cafb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset doesn't have validation checks yet!\n",
      "taking first 16 train samples\n",
      "taking first 16 val samples\n",
      "taking first 16 test samples\n"
     ]
    }
   ],
   "source": [
    "dataset = AmazonDataset(\n",
    "    data_dir, raw_data_file, tokenizer_name, tokenizer_cache_dir, preprocessing_num_workers=None,\n",
    "    processed_data_dir=processed_data_dir, split_file=split_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f68daf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model_path = \"/data/ddmg/redditlanguagemodeling/results/amazon_reviews/debug/large_test/42/pytorch_model.bin\"\n",
    "config_path = \"/data/ddmg/redditlanguagemodeling/results/amazon_reviews/debug/large_test/42/config.json\"\n",
    "model_cache_dir = \"/data/ddmg/redditlanguagemodeling/cached/distilbert_clf\"\n",
    "save_path = \"/data/ddmg/redditlanguagemodeling/data/AmazonReviews/data/amazon_v2.0/amazon_reviews_embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ed0a7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.10 (default, May 19 2021, 18:05:58) \n",
      "Type 'copyright', 'credits' or 'license' for more information\n",
      "IPython 7.22.0 -- An enhanced Interactive Python. Type '?' for help.\n",
      "\n",
      "In [1]: embeds.shape\n",
      "Out[1]: (16, 768)\n",
      "\n",
      "In [2]: embeds\n",
      "Out[2]: \n",
      "array([[-0.05110887,  0.16008174,  0.0036843 , ..., -0.22673766,\n",
      "         0.21907237,  0.07421229],\n",
      "       [-0.06776078,  0.09016232, -0.06899072, ..., -0.14116351,\n",
      "         0.24156968, -0.0708747 ],\n",
      "       [-0.13600317,  0.1055288 , -0.01967459, ..., -0.1403994 ,\n",
      "         0.2766955 , -0.06659016],\n",
      "       ...,\n",
      "       [-0.05227019,  0.19185911,  0.03148876, ..., -0.2325302 ,\n",
      "         0.20067655,  0.0534843 ],\n",
      "       [-0.01026849,  0.113495  , -0.03886039, ..., -0.15344343,\n",
      "         0.25235298, -0.00543861],\n",
      "       [-0.03850715,  0.17150235, -0.07424626, ..., -0.14239831,\n",
      "         0.28560936, -0.09876818]], dtype=float32)\n",
      "\n",
      "In [3]: %exit_raise\n",
      "\n"
     ]
    },
    {
     "ename": "KillEmbedded",
     "evalue": "Embedded IPython raising error, as user requested.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKillEmbedded\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1f7b8ff29dcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m dataset.embed_data(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0membed_model_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel_cache_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/data/ddmg/redditlanguagemodeling/reddit-personalized-lm/notebooks/AmazonReview_experiments/../../src/generic/dataset/language_dataset.py\u001b[0m in \u001b[0;36membed_data\u001b[0;34m(self, embed_model_path, config_path, model_cache_dir, save_path)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_model_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_cache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_embed_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_cache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embed_data_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embed_data_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embed_data_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/ddmg/redditlanguagemodeling/reddit-personalized-lm/notebooks/AmazonReview_experiments/../../src/generic/dataset/language_dataset.py\u001b[0m in \u001b[0;36m_embed_data_helper\u001b[0;34m(self, split_dataset)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0membedded_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded_batch\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0membeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedded_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0msplit_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"embeddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msplit_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rlm/lib/python3.8/site-packages/IPython/terminal/embed.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m     shell = InteractiveShellEmbed.instance(_init_location_id='%s:%s' % (\n\u001b[1;32m    387\u001b[0m         frame.f_code.co_filename, frame.f_lineno), **kwargs)\n\u001b[0;32m--> 388\u001b[0;31m     shell(header=header, stack_depth=2, compile_flags=compile_flags,\n\u001b[0m\u001b[1;32m    389\u001b[0m         _call_location_id='%s:%s' % (frame.f_code.co_filename, frame.f_lineno))\n\u001b[1;32m    390\u001b[0m     \u001b[0mInteractiveShellEmbed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rlm/lib/python3.8/site-packages/IPython/terminal/embed.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, header, local_ns, module, dummy, stack_depth, global_ns, compile_flags, **kw)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKillEmbedded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Embedded IPython raising error, as user requested.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKillEmbedded\u001b[0m: Embedded IPython raising error, as user requested."
     ]
    }
   ],
   "source": [
    "dataset.embed_data(\n",
    "    embed_model_path,\n",
    "    config_path,\n",
    "    model_cache_dir,\n",
    "    save_path=save_path\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
