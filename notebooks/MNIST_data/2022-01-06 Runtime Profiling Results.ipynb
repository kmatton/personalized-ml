{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e09a2472",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d121367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "696a7940",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"/data/ddmg/redditlanguagemodeling/reddit-personalized-lm/src/generic/profiling\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15939806",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "I think based on this I need to stop re-initializing the dataloader every time I train a user-specific model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279e57bc",
   "metadata": {},
   "source": [
    "### TO-DOS\n",
    "* I may want to implement an eval dataloader where you can specify which user to sample from at a given time (vs having a dataloader for each eval user)\n",
    "* Don't do meta learning based training during evaluation of models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b347a76",
   "metadata": {},
   "source": [
    "## Profile 1\n",
    "\n",
    "No adaptations to initial implementation\n",
    "\n",
    "Total train time: 4143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03431b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pstats.Stats(os.path.join(results_dir, \"profile1.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b5eb045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan  5 15:14:46 2022    /data/ddmg/redditlanguagemodeling/reddit-personalized-lm/src/generic/profiling/profile1.txt\n",
      "\n",
      "         880873920 function calls (878967844 primitive calls) in 4216.780 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 12614 to 20 due to restriction <20>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   3421/1    0.161    0.000 4216.845 4216.845 {built-in method builtins.exec}\n",
      "        1    0.002    0.002 4216.844 4216.844 runners/run_exp.py:1(<module>)\n",
      "        1    0.000    0.000 4200.363 4200.363 runners/run_exp.py:327(main)\n",
      "        1    0.000    0.000 4200.258 4200.258 runners/run_exp.py:206(run)\n",
      "        1    0.000    0.000 4199.668 4199.668 runners/run_exp.py:305(_loop_through_seeds)\n",
      "        1    0.000    0.000 4199.668 4199.668 runners/run_exp.py:182(run_single_seed)\n",
      "        1    0.000    0.000 4196.387 4196.387 runners/run_exp.py:189(run_single_exp)\n",
      "      609   26.459    0.043 4176.277    6.858 /data/ddmg/redditlanguagemodeling/reddit-personalized-lm/src/generic/trainers/user_weight_trainer_meta.py:250(pred_model_train)\n",
      "        1    0.001    0.001 4143.497 4143.497 runners/run_exp.py:106(train)\n",
      "        1   13.334   13.334 4143.484 4143.484 /data/ddmg/redditlanguagemodeling/reddit-personalized-lm/src/generic/trainers/user_weight_trainer_meta.py:107(train)\n",
      "     8193    0.103    0.000 1562.345    0.191 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:342(__iter__)\n",
      "     8193    0.196    0.000 1562.242    0.191 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:296(_get_iterator)\n",
      "     8193    5.902    0.001 1561.872    0.191 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:873(__init__)\n",
      "    32772    2.409    0.000 1464.317    0.045 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/multiprocessing/process.py:110(start)\n",
      "    32772    0.477    0.000 1460.816    0.045 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/multiprocessing/context.py:222(_Popen)\n",
      "    32772    0.884    0.000 1460.321    0.045 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/multiprocessing/context.py:274(_Popen)\n",
      "    32772    1.037    0.000 1459.258    0.045 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/multiprocessing/popen_fork.py:15(__init__)\n",
      "    32772    3.555    0.000 1456.935    0.044 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/multiprocessing/popen_fork.py:66(_launch)\n",
      "    32772 1448.237    0.044 1449.684    0.044 {built-in method posix.fork}\n",
      "     3801    3.197    0.001 1177.781    0.310 /data/ddmg/redditlanguagemodeling/reddit-personalized-lm/src/generic/trainers/user_weight_trainer_meta.py:334(pred_model_evaluate)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f602c49a5e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.sort_stats('cumulative').print_stats(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390acb55",
   "metadata": {},
   "source": [
    "## Profile 2\n",
    "\n",
    "Moving initialization of data loader out of inner loop\n",
    "\n",
    "Total train time: 4499"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74fa9170",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = pstats.Stats(os.path.join(results_dir, \"profile2.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77d6cee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan  6 11:22:28 2022    /data/ddmg/redditlanguagemodeling/reddit-personalized-lm/src/generic/profiling/profile2.txt\n",
      "\n",
      "         880670279 function calls (878769964 primitive calls) in 4563.215 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 12615 to 40 due to restriction <40>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   3421/1    0.118    0.000 4563.278 4563.278 {built-in method builtins.exec}\n",
      "        1    0.001    0.001 4563.278 4563.278 runners/run_exp.py:1(<module>)\n",
      "        1    0.000    0.000 4558.422 4558.422 runners/run_exp.py:327(main)\n",
      "        1    0.000    0.000 4558.394 4558.394 runners/run_exp.py:206(run)\n",
      "        1    0.000    0.000 4557.954 4557.954 runners/run_exp.py:305(_loop_through_seeds)\n",
      "        1    0.000    0.000 4557.954 4557.954 runners/run_exp.py:182(run_single_seed)\n",
      "        1    0.000    0.000 4555.046 4555.046 runners/run_exp.py:189(run_single_exp)\n",
      "      609   29.742    0.049 4533.834    7.445 /data/ddmg/redditlanguagemodeling/reddit-personalized-lm/src/generic/trainers/user_weight_trainer_meta.py:253(pred_model_train)\n",
      "        1    0.000    0.000 4499.823 4499.823 runners/run_exp.py:106(train)\n",
      "        1   13.860   13.860 4499.809 4499.809 /data/ddmg/redditlanguagemodeling/reddit-personalized-lm/src/generic/trainers/user_weight_trainer_meta.py:109(train)\n",
      "     8193    0.108    0.000 1757.086    0.214 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:342(__iter__)\n",
      "     8193    0.221    0.000 1756.978    0.214 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:296(_get_iterator)\n",
      "     8193    6.142    0.001 1754.227    0.214 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:873(__init__)\n",
      "    32772    2.580    0.000 1657.551    0.051 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/multiprocessing/process.py:110(start)\n",
      "    32772    0.651    0.000 1653.863    0.050 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/multiprocessing/context.py:222(_Popen)\n",
      "    32772    0.837    0.000 1653.193    0.050 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/multiprocessing/context.py:274(_Popen)\n",
      "    32772    0.900    0.000 1652.276    0.050 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/multiprocessing/popen_fork.py:15(__init__)\n",
      "    32772    3.454    0.000 1650.074    0.050 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/multiprocessing/popen_fork.py:66(_launch)\n",
      "    32772 1641.271    0.050 1642.711    0.050 {built-in method posix.fork}\n",
      "     3801    3.106    0.001 1260.334    0.332 /data/ddmg/redditlanguagemodeling/reddit-personalized-lm/src/generic/trainers/user_weight_trainer_meta.py:336(pred_model_evaluate)\n",
      "    97845    1.848    0.000  973.469    0.010 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:513(__next__)\n",
      "    97845    1.082    0.000  962.175    0.010 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1152(_next_data)\n",
      "    72048    2.475    0.000  863.394    0.012 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/higher/optim.py:149(step)\n",
      "    72648  854.000    0.012  854.000    0.012 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
      "  1560328    7.244    0.000  686.331    0.000 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/traceback.py:193(format_stack)\n",
      "    72048    0.609    0.000  594.498    0.008 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/autograd/__init__.py:150(grad)\n",
      "    16386    0.800    0.000  554.759    0.034 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1254(_shutdown_workers)\n",
      "    32772    0.270    0.000  544.395    0.017 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/multiprocessing/process.py:142(join)\n",
      "    32772    0.471    0.000  544.021    0.017 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/multiprocessing/popen_fork.py:40(wait)\n",
      "    32772    0.475    0.000  542.186    0.017 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/multiprocessing/connection.py:917(wait)\n",
      "    32772    0.493    0.000  540.605    0.016 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/selectors.py:402(select)\n",
      "    32772  539.553    0.016  539.825    0.016 {method 'poll' of 'select.poll' objects}\n",
      "717216/179304    9.506    0.000  477.739    0.003 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/modules/module.py:866(_call_impl)\n",
      "  1560354    5.324    0.000  462.416    0.000 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/traceback.py:200(extract_stack)\n",
      "  1560354  113.223    0.000  456.661    0.000 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/traceback.py:321(extract)\n",
      "   677736  422.502    0.001  422.502    0.001 {method 'acquire' of '_thread.lock' objects}\n",
      "    77610    0.679    0.000  421.391    0.005 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/threading.py:270(wait)\n",
      "    89652    0.397    0.000  402.802    0.004 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1119(_get_data)\n",
      "    89652    0.287    0.000  401.841    0.004 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:973(_try_get_data)\n",
      "    89664    0.978    0.000  401.554    0.004 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/queue.py:153(get)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f601716e3d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2.sort_stats('cumulative').print_stats(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc656a7",
   "metadata": {},
   "source": [
    "## Profile 3\n",
    "\n",
    "Training personalized models with basic trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a87010df",
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = pstats.Stats(os.path.join(results_dir, \"profile3.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d948dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan  6 16:02:46 2022    /data/ddmg/redditlanguagemodeling/reddit-personalized-lm/src/generic/profiling/profile3.txt\n",
      "\n",
      "         2609020 function calls (2512484 primitive calls) in 20.780 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 12605 to 40 due to restriction <40>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   3421/1    0.128    0.000   20.785   20.785 {built-in method builtins.exec}\n",
      "        1    0.000    0.000   20.785   20.785 runners/run_exp.py:1(<module>)\n",
      "        1    0.000    0.000   16.212   16.212 runners/run_exp.py:327(main)\n",
      "        1    0.001    0.001   16.184   16.184 runners/run_exp.py:214(run_personalized)\n",
      "        3    0.000    0.000   15.652    5.217 runners/run_exp.py:305(_loop_through_seeds)\n",
      "        3    0.000    0.000   15.652    5.217 runners/run_exp.py:182(run_single_seed)\n",
      "        3    0.000    0.000   13.028    4.343 runners/run_exp.py:189(run_single_exp)\n",
      "        3    0.000    0.000   10.872    3.624 runners/run_exp.py:106(train)\n",
      "        3    0.000    0.000   10.835    3.612 /data/ddmg/redditlanguagemodeling/reddit-personalized-lm/src/generic/trainers/basic_trainer.py:139(train)\n",
      "        3    0.006    0.002   10.826    3.609 /data/ddmg/redditlanguagemodeling/reddit-personalized-lm/src/generic/trainers/basic_trainer.py:239(_train_loop)\n",
      "       28    0.021    0.001   10.757    0.384 /data/ddmg/redditlanguagemodeling/reddit-personalized-lm/src/generic/trainers/basic_trainer.py:269(evaluate)\n",
      "       22    0.003    0.000    8.752    0.398 /data/ddmg/redditlanguagemodeling/reddit-personalized-lm/src/generic/trainers/basic_trainer.py:555(_maybe_log_save_evaluate)\n",
      "       33    0.000    0.000    7.543    0.229 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:342(__iter__)\n",
      "       33    0.001    0.000    7.543    0.229 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:296(_get_iterator)\n",
      "       33    0.027    0.001    7.542    0.229 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:873(__init__)\n",
      "      132    0.011    0.000    7.144    0.054 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/multiprocessing/process.py:110(start)\n",
      "      132    0.003    0.000    7.122    0.054 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/multiprocessing/context.py:222(_Popen)\n",
      "      132    0.005    0.000    7.120    0.054 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/multiprocessing/context.py:274(_Popen)\n",
      "      132    0.004    0.000    7.114    0.054 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/multiprocessing/popen_fork.py:15(__init__)\n",
      "      132    0.016    0.000    7.105    0.054 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/multiprocessing/popen_fork.py:66(_launch)\n",
      "      132    7.057    0.053    7.068    0.054 {built-in method posix.fork}\n",
      "  2531/15    0.018    0.000    4.558    0.304 <frozen importlib._bootstrap>:986(_find_and_load)\n",
      "  2512/13    0.014    0.000    4.558    0.351 <frozen importlib._bootstrap>:956(_find_and_load_unlocked)\n",
      "  2414/16    0.015    0.000    4.550    0.284 <frozen importlib._bootstrap>:650(_load_unlocked)\n",
      "  2179/13    0.009    0.000    4.549    0.350 <frozen importlib._bootstrap_external>:842(exec_module)\n",
      "  3104/16    0.003    0.000    4.544    0.284 <frozen importlib._bootstrap>:211(_call_with_frames_removed)\n",
      "      164    0.005    0.000    4.307    0.026 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:513(__next__)\n",
      "      164    0.002    0.000    4.278    0.026 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1152(_next_data)\n",
      "2680/1062    0.006    0.000    3.070    0.003 <frozen importlib._bootstrap>:1017(_handle_fromlist)\n",
      "  836/260    0.003    0.000    2.921    0.011 {built-in method builtins.__import__}\n",
      "        3    0.000    0.000    2.625    0.875 runners/run_exp.py:85(setup_exp)\n",
      "        3    0.000    0.000    2.612    0.871 /data/ddmg/redditlanguagemodeling/reddit-personalized-lm/src/generic/common/factories.py:213(get_trainer)\n",
      "        3    0.000    0.000    2.611    0.870 /data/ddmg/redditlanguagemodeling/reddit-personalized-lm/src/generic/trainers/basic_trainer.py:45(__init__)\n",
      "      416    2.546    0.006    2.546    0.006 {method 'to' of 'torch._C._TensorBase' objects}\n",
      "        3    0.000    0.000    2.527    0.842 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/modules/module.py:573(to)\n",
      "     18/3    0.000    0.000    2.527    0.842 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/modules/module.py:385(_apply)\n",
      "       12    0.000    0.000    2.526    0.211 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/nn/modules/module.py:667(convert)\n",
      "     2135    2.293    0.001    2.293    0.001 {method 'acquire' of '_thread.lock' objects}\n",
      "      323    0.003    0.000    2.291    0.007 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/threading.py:270(wait)\n",
      "       63    0.003    0.000    2.251    0.036 /data/ddmg/users/kmatton/.conda/envs/rlm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1254(_shutdown_workers)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f602fd75bb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3.sort_stats('cumulative').print_stats(40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
