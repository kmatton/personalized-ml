{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b57efe3",
   "metadata": {},
   "source": [
    "## Dataset Details\n",
    "\n",
    "All users input data is 0,1 MNIST images.\n",
    "\n",
    "User 1 and User 2: 0 is negative and 1 is positive class.\n",
    "\n",
    "User 3: labels are random 0/1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "658a0d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34447dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acff051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95f3aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "756b82f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/data/ddmg/redditlanguagemodeling/data/MNIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5a4964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(root=data_path, train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb9ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = datasets.MNIST(root=data_path, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "373af5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_indices = (mnist_train.targets == 0) | (mnist_train.targets == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e84a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train.data, mnist_train.targets = mnist_train.data[keep_indices], mnist_train.targets[keep_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dffb233",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_indices = (mnist_test.targets == 0) | (mnist_test.targets == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3209ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test.data, mnist_test.targets = mnist_test.data[keep_indices], mnist_test.targets[keep_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e6e9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break up into 3 sets for each user and save as numpy arrays\n",
    "# each user has 200 train, 100 val, 100 test examples\n",
    "\n",
    "user_1_train_x, user_1_train_y = mnist_train.data[:200].flatten(1,2), mnist_train.targets[:200]\n",
    "user_2_train_x, user_2_train_y = mnist_train.data[200:400].flatten(1,2), mnist_train.targets[200:400]\n",
    "user_3_train_x, user_3_train_y = mnist_train.data[400:600].flatten(1,2), mnist_train.targets[400:600]\n",
    "user_1_val_x, user_1_val_y = mnist_train.data[600:700].flatten(1,2), mnist_train.targets[600:700]\n",
    "user_2_val_x, user_2_val_y = mnist_train.data[700:800].flatten(1,2), mnist_train.targets[700:800]\n",
    "user_3_val_x, user_3_val_y = mnist_train.data[800:900].flatten(1,2), mnist_train.targets[800:900]\n",
    "user_1_test_x, user_1_test_y = mnist_test.data[:100].flatten(1,2), mnist_test.targets[:100]\n",
    "user_2_test_x, user_2_test_y = mnist_test.data[100:200].flatten(1,2), mnist_test.targets[100:200]\n",
    "p = torch.full((100, 1), 0.5)\n",
    "user_3_test_x, user_3_test_y = mnist_test.data[200:300].flatten(1,2), torch.bernoulli(p).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "051a9c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_path = os.path.join(data_path, \"dummmy_test1\")\n",
    "save_path1 = os.path.join(save_data_path, \"user1\")\n",
    "save_path2 = os.path.join(save_data_path, \"user2\")\n",
    "save_path3 = os.path.join(save_data_path, \"user3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43585064",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(user_1_train_x, os.path.join(save_path1, 'train_x.pt'))\n",
    "torch.save(user_1_train_y, os.path.join(save_path1, 'train_y.pt'))\n",
    "torch.save(user_1_val_x, os.path.join(save_path1, 'val_x.pt'))\n",
    "torch.save(user_1_val_y, os.path.join(save_path1, 'val_y.pt'))\n",
    "torch.save(user_1_test_x, os.path.join(save_path1, 'test_x.pt'))\n",
    "torch.save(user_1_test_y, os.path.join(save_path1, 'test_y.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc4cf620",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(user_2_train_x, os.path.join(save_path2, 'train_x.pt'))\n",
    "torch.save(user_2_train_y, os.path.join(save_path2, 'train_y.pt'))\n",
    "torch.save(user_2_val_x, os.path.join(save_path2, 'val_x.pt'))\n",
    "torch.save(user_2_val_y, os.path.join(save_path2, 'val_y.pt'))\n",
    "torch.save(user_2_test_x, os.path.join(save_path2, 'test_x.pt'))\n",
    "torch.save(user_2_test_y, os.path.join(save_path2, 'test_y.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0b09b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(user_3_train_x, os.path.join(save_path3, 'train_x.pt'))\n",
    "torch.save(user_3_train_y, os.path.join(save_path3, 'train_y.pt'))\n",
    "torch.save(user_3_val_x, os.path.join(save_path3, 'val_x.pt'))\n",
    "torch.save(user_3_val_y, os.path.join(save_path3, 'val_y.pt'))\n",
    "torch.save(user_3_test_x, os.path.join(save_path3, 'test_x.pt'))\n",
    "torch.save(user_3_test_y, os.path.join(save_path3, 'test_y.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc19a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dict and then save as json file\n",
    "data_list = []\n",
    "for (x, y) in zip(user_1_train_x, user_1_train_y):\n",
    "    row_dict = {\"x\": x.tolist(), \"y\": y.item(), \"split\": \"train\", \"user\": 1}\n",
    "    data_list.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee0c555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y) in zip(user_1_val_x, user_1_val_y):\n",
    "    row_dict = {\"x\": x.tolist(), \"y\": y.item(), \"split\": \"val\", \"user\": 1}\n",
    "    data_list.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79527986",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y) in zip(user_1_test_x, user_1_test_y):\n",
    "    row_dict = {\"x\": x.tolist(), \"y\": y.item(), \"split\": \"test\", \"user\": 1}\n",
    "    data_list.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d744c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y) in zip(user_2_train_x, user_2_train_y):\n",
    "    row_dict = {\"x\": x.tolist(), \"y\": y.item(), \"split\": \"train\", \"user\": 2}\n",
    "    data_list.append(row_dict)\n",
    "    \n",
    "for (x, y) in zip(user_2_val_x, user_2_val_y):\n",
    "    row_dict = {\"x\": x.tolist(), \"y\": y.item(), \"split\": \"val\", \"user\": 2}\n",
    "    data_list.append(row_dict)\n",
    "    \n",
    "for (x, y) in zip(user_2_test_x, user_2_test_y):\n",
    "    row_dict = {\"x\": x.tolist(), \"y\": y.item(), \"split\": \"test\", \"user\": 2}\n",
    "    data_list.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7a9fec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y) in zip(user_3_train_x, user_3_train_y):\n",
    "    row_dict = {\"x\": x.tolist(), \"y\": y.item(), \"split\": \"train\", \"user\": 3}\n",
    "    data_list.append(row_dict)\n",
    "    \n",
    "for (x, y) in zip(user_3_val_x, user_3_val_y):\n",
    "    row_dict = {\"x\": x.tolist(), \"y\": y.item(), \"split\": \"val\", \"user\": 3}\n",
    "    data_list.append(row_dict)\n",
    "    \n",
    "for (x, y) in zip(user_3_test_x, user_3_test_y):\n",
    "    row_dict = {\"x\": x.tolist(), \"y\": y.item(), \"split\": \"test\", \"user\": 3}\n",
    "    data_list.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d47c0c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\"version\": \"21.22.10\", \"data\": data_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96bdd878",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'json' has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-9dca34d9e460>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dummmy_test1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"full_data.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'json' has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(data_path, \"dummmy_test1\", \"full_data.json\"), \"w\") as f:\n",
    "    json.dump(data_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
