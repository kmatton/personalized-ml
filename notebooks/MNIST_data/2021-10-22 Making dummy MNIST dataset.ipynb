{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c716c7",
   "metadata": {},
   "source": [
    "## Dataset Details\n",
    "\n",
    "All users input data is 0,1 MNIST images.\n",
    "\n",
    "User 1 and User 2: 0 is negative and 1 is positive class.\n",
    "\n",
    "User 3: labels are random 0/1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea1e23e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df3e3a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de7708c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6945c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "259c0a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/data/ddmg/redditlanguagemodeling/data/MNIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f5da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(root=data_path, train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abe80d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = datasets.MNIST(root=data_path, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08d26736",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_indices = (mnist_train.targets == 0) | (mnist_train.targets == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d595122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train.data, mnist_train.targets = mnist_train.data[keep_indices], mnist_train.targets[keep_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52e66b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_indices = (mnist_test.targets == 0) | (mnist_test.targets == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c8616d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test.data, mnist_test.targets = mnist_test.data[keep_indices], mnist_test.targets[keep_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6efdb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break up into 3 sets for each user and save as numpy arrays\n",
    "# each user has 200 train, 100 val, 100 test examples\n",
    "\n",
    "user_1_train_x, user_1_train_y = mnist_train.data[:200].flatten(1,2), mnist_train.targets[:200]\n",
    "user_2_train_x, user_2_train_y = mnist_train.data[200:400].flatten(1,2), mnist_train.targets[200:400]\n",
    "user_3_train_x, user_3_train_y = mnist_train.data[400:600].flatten(1,2), mnist_train.targets[400:600]\n",
    "user_1_val_x, user_1_val_y = mnist_train.data[600:700].flatten(1,2), mnist_train.targets[600:700]\n",
    "user_2_val_x, user_2_val_y = mnist_train.data[700:800].flatten(1,2), mnist_train.targets[700:800]\n",
    "user_3_val_x, user_3_val_y = mnist_train.data[800:900].flatten(1,2), mnist_train.targets[800:900]\n",
    "user_1_test_x, user_1_test_y = mnist_test.data[:100].flatten(1,2), mnist_test.targets[:100]\n",
    "user_2_test_x, user_2_test_y = mnist_test.data[100:200].flatten(1,2), mnist_test.targets[100:200]\n",
    "p = torch.full((100, 1), 0.5)\n",
    "user_3_test_x, user_3_test_y = mnist_test.data[200:300].flatten(1,2), torch.bernoulli(p).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "138dc8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_path = os.path.join(data_path, \"dummmy_test1\")\n",
    "save_path1 = os.path.join(save_data_path, \"user1\")\n",
    "save_path2 = os.path.join(save_data_path, \"user2\")\n",
    "save_path3 = os.path.join(save_data_path, \"user3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c45aaa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(user_1_train_x, os.path.join(save_path1, 'train_x.pt'))\n",
    "torch.save(user_1_train_y, os.path.join(save_path1, 'train_y.pt'))\n",
    "torch.save(user_1_val_x, os.path.join(save_path1, 'val_x.pt'))\n",
    "torch.save(user_1_val_y, os.path.join(save_path1, 'val_y.pt'))\n",
    "torch.save(user_1_test_x, os.path.join(save_path1, 'test_x.pt'))\n",
    "torch.save(user_1_test_y, os.path.join(save_path1, 'test_y.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18b8c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(user_2_train_x, os.path.join(save_path2, 'train_x.pt'))\n",
    "torch.save(user_2_train_y, os.path.join(save_path2, 'train_y.pt'))\n",
    "torch.save(user_2_val_x, os.path.join(save_path2, 'val_x.pt'))\n",
    "torch.save(user_2_val_y, os.path.join(save_path2, 'val_y.pt'))\n",
    "torch.save(user_2_test_x, os.path.join(save_path2, 'test_x.pt'))\n",
    "torch.save(user_2_test_y, os.path.join(save_path2, 'test_y.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84b37db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(user_3_train_x, os.path.join(save_path3, 'train_x.pt'))\n",
    "torch.save(user_3_train_y, os.path.join(save_path3, 'train_y.pt'))\n",
    "torch.save(user_3_val_x, os.path.join(save_path3, 'val_x.pt'))\n",
    "torch.save(user_3_val_y, os.path.join(save_path3, 'val_y.pt'))\n",
    "torch.save(user_3_test_x, os.path.join(save_path3, 'test_x.pt'))\n",
    "torch.save(user_3_test_y, os.path.join(save_path3, 'test_y.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbf0ec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dict and then save as json file\n",
    "data_list = []\n",
    "for (x, y) in zip(user_1_train_x, user_1_train_y):\n",
    "    row_dict = {\"x\": x.tolist(), \"y\": y.item(), \"split\": \"train\", \"user\": 1}\n",
    "    data_list.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50ccff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y) in zip(user_1_val_x, user_1_val_y):\n",
    "    row_dict = {\"x\": x.tolist(), \"y\": y.item(), \"split\": \"val\", \"user\": 1}\n",
    "    data_list.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b6bf82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y) in zip(user_1_test_x, user_1_test_y):\n",
    "    row_dict = {\"x\": x.tolist(), \"y\": y.item(), \"split\": \"test\", \"user\": 1}\n",
    "    data_list.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd21f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y) in zip(user_2_train_x, user_2_train_y):\n",
    "    row_dict = {\"x\": x.tolist(), \"y\": y.item(), \"split\": \"train\", \"user\": 2}\n",
    "    data_list.append(row_dict)\n",
    "    \n",
    "for (x, y) in zip(user_2_val_x, user_2_val_y):\n",
    "    row_dict = {\"x\": x.tolist(), \"y\": y.item(), \"split\": \"val\", \"user\": 2}\n",
    "    data_list.append(row_dict)\n",
    "    \n",
    "for (x, y) in zip(user_2_test_x, user_2_test_y):\n",
    "    row_dict = {\"x\": x.tolist(), \"y\": y.item(), \"split\": \"test\", \"user\": 2}\n",
    "    data_list.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc1ea22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y) in zip(user_3_train_x, user_3_train_y):\n",
    "    row_dict = {\"x\": x.tolist(), \"y\": y.item(), \"split\": \"train\", \"user\": 3}\n",
    "    data_list.append(row_dict)\n",
    "    \n",
    "for (x, y) in zip(user_3_val_x, user_3_val_y):\n",
    "    row_dict = {\"x\": x.tolist(), \"y\": y.item(), \"split\": \"val\", \"user\": 3}\n",
    "    data_list.append(row_dict)\n",
    "    \n",
    "for (x, y) in zip(user_3_test_x, user_3_test_y):\n",
    "    row_dict = {\"x\": x.tolist(), \"y\": y.item(), \"split\": \"test\", \"user\": 3}\n",
    "    data_list.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d3b36bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\"version\": \"21.22.10\", \"data\": data_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26a2831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, \"dummmy_test1\", \"full_data.json\"), \"w\") as f:\n",
    "    json.dump(data_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
